---
title: "Week6_HW_JianghongMan"
author: "Jianghong Man"
date: "11/9/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
dataPath <- "/Users/nimo/Desktop/31007/6/HW6/statistics_06_data/"
train_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Train.csv',sep = '/'), header=TRUE)
```

```{r}
nSample.Training<-length(train_dat[,1])
head(train_dat)
```

```{r}
plot(train_dat[,1],train_dat[,2], type="p",pch=19)
```

```{r}
# Define training samples generated by model 1 and model 2
train_dat.1<-cbind(train_dat[,1],rep(NA,nSample.Training))
train_dat.2<-cbind(train_dat[,1],rep(NA,nSample.Training))
train_dat.1[train_dat[,3]*(1:nSample.Training),2]<-
  train_dat[train_dat[,3]*(1:nSample.Training),2]
train_dat.2[(1-train_dat[,3])*(1:nSample.Training),2]<-
  train_dat[(1-train_dat[,3])*(1:nSample.Training),2]

head(cbind(train_dat,
           Trainig1=train_dat.1[,2],
           Training2=train_dat.2[,2]))
```

```{r}
# Plot the subsamples
matplot(train_dat[,1],cbind(train_dat.1[,2],train_dat.2[,2]),
        pch=16,col=c("green","blue"),ylab="Subsamples of the training sample")
```

```{r}
EstimatedLinearModel.Training <- lm(Output~Input,train_dat)
summary(EstimatedLinearModel.Training)$coefficients
```

```{r}
summary(EstimatedLinearModel.Training)$r.squared
```

```{r}
summary(EstimatedLinearModel.Training)$sigma
```

```{r}
EstimatedResiduals.Training<-EstimatedLinearModel.Training$residuals
plot(train_dat[,1],EstimatedResiduals.Training)
```

```{r}
# Define residuals corresponding to different models 
EstimatedResiduals.Training.1<-EstimatedResiduals.Training
EstimatedResiduals.Training.2<-EstimatedResiduals.Training
EstimatedResiduals.Training.1[(train_dat[,3]==0)*(1:nSample.Training)]<-NA
EstimatedResiduals.Training.2[(train_dat[,3]==1)*(1:nSample.Training)]<-NA
# Print the first ten columns to check the separation 
head(cbind(AllResiduals=EstimatedResiduals.Training,
      Training1Residuals=EstimatedResiduals.Training.1,
      Training2Residuals=EstimatedResiduals.Training.2,
      TrainingClass=train_dat[,3]))
```

```{r}
# Plot the residuals corresponding to different models
matplot(train_dat[,1],cbind(EstimatedResiduals.Training.1,
                                       EstimatedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Separated parts of the training sample")
```

# Logistic regression 

```{r}
# Create the data frame for logistic regression
Logistic.Model.Data<-data.frame(Logistic.Output=train_dat[,3],
                                Logistic.Input=EstimatedResiduals.Training)
LinearModel.Training.Logistic<-glm(Logistic.Output~Logistic.Input,data=Logistic.Model.Data,
                                   family=binomial(link=logit))
summary(LinearModel.Training.Logistic)
```

```{r}
names(LinearModel.Training.Logistic)
```

```{r}
Predicted.Probabilities.Training<-predict(LinearModel.Training.Logistic,type="response")
plot(train_dat[,1],Predicted.Probabilities.Training)
```

```{r}
# Create the unscrambling sequence for the training sample
Unscrambling.Sequence.Training.Logistic<-
  (predict(LinearModel.Training.Logistic,type="response")>.5)*1
# Create classified residuals
ClassifiedResiduals.Training.1<-EstimatedResiduals.Training
ClassifiedResiduals.Training.2<-EstimatedResiduals.Training
ClassifiedResiduals.Training.1[(Unscrambling.Sequence.Training.Logistic==0)*
                                 (1:nSample.Training)]<-NA
ClassifiedResiduals.Training.2[(Unscrambling.Sequence.Training.Logistic==1)*
                                 (1:nSample.Training)]<-NA
head(cbind(AllTraining=EstimatedResiduals.Training,
           Training1=ClassifiedResiduals.Training.1,
           Training2=ClassifiedResiduals.Training.2,
           TrainingClass=train_dat[,3]))
```

```{r}
# Plot both classes of the residuals
matplot(train_dat[,1],cbind(ClassifiedResiduals.Training.1,
                                       ClassifiedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Classified residuals, X-axis at 0")
axis(1,pos=0)
```

```{r}
Classification.Rule.Logistic <- -LinearModel.Training.Logistic$coefficients[1] / LinearModel.Training.Logistic$coefficients[2]

Classification.Rule.Logistic
```

```{r}
matplot(train_dat[,1],cbind(ClassifiedResiduals.Training.1,
                                       ClassifiedResiduals.Training.2),
        pch=16,col=c("green","blue"),ylab="Classified residuals, X-axis at the rule level")
axis(1,pos=Classification.Rule.Logistic)
```

# 1.3 Separate subsamples in the main sample using the classifier trained on the training sample

```{r}
main_dat <- read.table(paste(dataPath,'Week6_Test_Sample_Test.csv',sep = '/'), header=TRUE)
nSample<-length(main_dat[,1])
head(main_dat)
```

```{r}
EstimatedLinearModel<-lm(main_dat[,1]~main_dat[,2])
```

```{r}
EstimatedLinearModel$coefficients
```

```{r}
EstimatedResiduals<-EstimatedLinearModel$residuals
plot(main_dat[,1],EstimatedResiduals)
```


```{r}
Unscrambling.Sequence.Logistic<-(predict(LinearModel.Training.Logistic,                               
                                         newdata=data.frame(Logistic.Output=EstimatedResiduals,                   
                                                            Logistic.Input=EstimatedResiduals),
                                         type="response")>.5)*1
```

















```{r}
res <- list(Unscrambling.Sequence.Logistic =  Unscrambling.Sequence.Logistic)
```

```{r}
write.table(res, file = paste(dataPath,'result.csv',sep = '/'), row.names = F)
```


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import full data set using Pandas and verify the shape\n",
    "df = pd.read_excel('default of credit card clients.xls', usecols=lambda x: 'Unnamed' not in x,)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default payment next month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>689</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272</td>\n",
       "      <td>3455</td>\n",
       "      <td>3261</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331</td>\n",
       "      <td>14948</td>\n",
       "      <td>15549</td>\n",
       "      <td>1518</td>\n",
       "      <td>1500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314</td>\n",
       "      <td>28959</td>\n",
       "      <td>29547</td>\n",
       "      <td>2000</td>\n",
       "      <td>2019</td>\n",
       "      <td>1200</td>\n",
       "      <td>1100</td>\n",
       "      <td>1069</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940</td>\n",
       "      <td>19146</td>\n",
       "      <td>19131</td>\n",
       "      <td>2000</td>\n",
       "      <td>36681</td>\n",
       "      <td>10000</td>\n",
       "      <td>9000</td>\n",
       "      <td>689</td>\n",
       "      <td>679</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0      20000    2          2         1   24      2      2     -1     -1   \n",
       "1     120000    2          2         2   26     -1      2      0      0   \n",
       "2      90000    2          2         2   34      0      0      0      0   \n",
       "3      50000    2          2         1   37      0      0      0      0   \n",
       "4      50000    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   PAY_5  ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0     -2  ...          0          0          0         0       689         0   \n",
       "1      0  ...       3272       3455       3261         0      1000      1000   \n",
       "2      0  ...      14331      14948      15549      1518      1500      1000   \n",
       "3      0  ...      28314      28959      29547      2000      2019      1200   \n",
       "4      0  ...      20940      19146      19131      2000     36681     10000   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default payment next month  \n",
       "0         0         0         0                           1  \n",
       "1      1000         0      2000                           1  \n",
       "2      1000      1000      5000                           0  \n",
       "3      1100      1069      1000                           0  \n",
       "4      9000       689       679                           0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 24)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove NaN / NA values from dataset\n",
    "df = df.dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30000, 23) (30000,)\n"
     ]
    }
   ],
   "source": [
    "# Create X & y objects \n",
    "cols = list(df.columns.values) \n",
    "cols.pop(cols.index('default payment next month')) \n",
    "X = df[cols] \n",
    "y = df['default payment next month']\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate X_train, X_test, y_train & y_test. Use 70% for train & 30% for test\n",
    "np.random.seed(42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random Forest Classifier - Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=42)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the RandomForestClassifier model on the training data\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[[0.72 0.28]\n",
      " [0.89 0.11]\n",
      " [0.67 0.33]\n",
      " [0.92 0.08]\n",
      " [0.77 0.23]\n",
      " [0.88 0.12]\n",
      " [0.54 0.46]\n",
      " [0.97 0.03]\n",
      " [0.96 0.04]\n",
      " [0.7  0.3 ]]\n",
      "[0.28 0.11 0.33 0.08 0.23 0.12 0.46 0.03 0.04 0.3 ]\n"
     ]
    }
   ],
   "source": [
    "# Use the fitted model to predict on test data. \n",
    "# Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes.\n",
    "y_pred = rf.predict(X_test)\n",
    "y_pred_proba = rf.predict_proba(X_test)\n",
    "y_pred_proba_answer = y_pred_proba[:,1]\n",
    "\n",
    "print(y_pred[:10])\n",
    "print(y_pred_proba[:10])\n",
    "print(y_pred_proba_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89      7040\n",
      "           1       0.62      0.36      0.46      1960\n",
      "\n",
      "    accuracy                           0.81      9000\n",
      "   macro avg       0.73      0.65      0.67      9000\n",
      "weighted avg       0.79      0.81      0.79      9000\n",
      "\n",
      "[[6611  429]\n",
      " [1251  709]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix and classification report \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7549265494550094\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc_auc_score for this model\n",
    "print(roc_auc_score(y_test, y_pred_proba_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0]\n",
      "[[0.3  0.7 ]\n",
      " [0.94 0.06]\n",
      " [0.81 0.19]\n",
      " [0.82 0.18]\n",
      " [0.99 0.01]\n",
      " [0.97 0.03]\n",
      " [0.98 0.02]\n",
      " [1.   0.  ]\n",
      " [0.91 0.09]\n",
      " [0.88 0.12]]\n",
      "[0.7  0.06 0.19 0.18 0.01 0.03 0.02 0.   0.09 0.12]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions for the training data & build the classification report & roc_auc_score. \n",
    "y_pred_train = rf.predict(X_train)\n",
    "y_pred_train_proba = rf.predict_proba(X_train)\n",
    "y_pred_train_proba_answer = y_pred_train_proba[:,1]\n",
    "\n",
    "print(y_pred_train[:10])\n",
    "print(y_pred_train_proba[:10])\n",
    "print(y_pred_train_proba_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     16324\n",
      "           1       1.00      1.00      1.00      4676\n",
      "\n",
      "    accuracy                           1.00     21000\n",
      "   macro avg       1.00      1.00      1.00     21000\n",
      "weighted avg       1.00      1.00      1.00     21000\n",
      "\n",
      "[[16320     4]\n",
      " [    7  4669]]\n",
      "0.9991289780155445\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_pred_train))\n",
    "print(confusion_matrix(y_train, y_pred_train))\n",
    "print(roc_auc_score(y_train, y_pred_train))\n",
    "\n",
    "# Are there signs of overfitting? Why or why not?\n",
    "# There is a sign of overfitting since the training accuracy is way higher than the testing one. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest Classifier - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple Random Forest only using default parameters.\n",
    "rf = RandomForestClassifier(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'ccp_alpha': 0.0,\n",
      " 'class_weight': None,\n",
      " 'criterion': 'gini',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'max_samples': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 100,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 42,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': [6, 8, 10, 12],\n",
      " 'max_features': [2, 4, 'sqrt'],\n",
      " 'min_samples_split': [3, 4, 5, 6, 7, 8],\n",
      " 'n_estimators': [50, 100, 500]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [50, 100, 500]\n",
    "# Number of features to consider at every split\n",
    "max_features = [2, 4, 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [6, 8, 10, 12]\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [3,4,5,6,7,8]\n",
    "\n",
    "# Create the random grid\n",
    "param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split}\n",
    "pprint(param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'max_depth': [6, 8, 10, 12],\n",
       "                         'max_features': [2, 4, 'sqrt'],\n",
       "                         'min_samples_split': [3, 4, 5, 6, 7, 8],\n",
       "                         'n_estimators': [50, 100, 500]},\n",
       "             scoring='roc_auc', verbose=5)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "# create Random Forest model \n",
    "rf_obj = RandomForestClassifier()\n",
    "\n",
    "# Create gridsearch object with various combinations of parameters\n",
    "rf_Grid = GridSearchCV(rf_obj, param_grid, cv = 5, scoring = 'roc_auc',\n",
    "                       refit = True, n_jobs=-1, verbose = 5)\n",
    "\n",
    "rf_Grid.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10, 'max_features': 4, 'min_samples_split': 7, 'n_estimators': 500}\n",
      "RandomForestClassifier(max_depth=10, max_features=4, min_samples_split=7,\n",
      "                       n_estimators=500)\n"
     ]
    }
   ],
   "source": [
    "# Identify the best performing model:\n",
    "best_param = rf_Grid.best_params_\n",
    "\n",
    "best_grid = rf_Grid.best_estimator_\n",
    "\n",
    "print(best_param)\n",
    "print(best_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[[0.83853749 0.16146251]\n",
      " [0.90934359 0.09065641]\n",
      " [0.87752101 0.12247899]\n",
      " [0.90371251 0.09628749]\n",
      " [0.80554047 0.19445953]\n",
      " [0.84623223 0.15376777]\n",
      " [0.62565533 0.37434467]\n",
      " [0.69393561 0.30606439]\n",
      " [0.93046707 0.06953293]\n",
      " [0.83968732 0.16031268]]\n",
      "[0.16146251 0.09065641 0.12247899 0.09628749 0.19445953 0.15376777\n",
      " 0.37434467 0.30606439 0.06953293 0.16031268]\n"
     ]
    }
   ],
   "source": [
    "# Use the best estimator model to predict on test data. \n",
    "# Use the .predict_proba() and the .predict() methods to get predicted probabilities as well as predicted classes.\n",
    "\n",
    "grid_y_pred = rf_Grid.predict(X_test)\n",
    "grid_y_pred_proba = rf_Grid.predict_proba(X_test)\n",
    "grid_y_pred_proba_answer = grid_y_pred_proba[:,1]\n",
    "\n",
    "print(grid_y_pred[:10])\n",
    "print(grid_y_pred_proba[:10])\n",
    "print(grid_y_pred_proba_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.95      0.89      7040\n",
      "           1       0.67      0.36      0.46      1960\n",
      "\n",
      "    accuracy                           0.82      9000\n",
      "   macro avg       0.75      0.65      0.68      9000\n",
      "weighted avg       0.80      0.82      0.80      9000\n",
      "\n",
      "[[6695  345]\n",
      " [1264  696]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate the confusion matrix and classification report \n",
    "print(classification_report(y_test, grid_y_pred))\n",
    "print(confusion_matrix(y_test, grid_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7749648147611318\n"
     ]
    }
   ],
   "source": [
    "# Calculate the roc_auc_score for this model.\n",
    "print(roc_auc_score(y_test, grid_y_pred_proba_answer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 0 0 0 0 0 0]\n",
      "[[0.69445038 0.30554962]\n",
      " [0.89218566 0.10781434]\n",
      " [0.44217063 0.55782937]\n",
      " [0.57807444 0.42192556]\n",
      " [0.92170609 0.07829391]\n",
      " [0.89437287 0.10562713]\n",
      " [0.92230391 0.07769609]\n",
      " [0.91134952 0.08865048]\n",
      " [0.85133978 0.14866022]\n",
      " [0.68946628 0.31053372]]\n",
      "[0.30554962 0.10781434 0.55782937 0.42192556 0.07829391 0.10562713\n",
      " 0.07769609 0.08865048 0.14866022 0.31053372]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions for the training data & build the confusion matrix, classification report & roc_auc_score. \n",
    "grid_y_pred_train = rf_Grid.predict(X_train)\n",
    "grid_y_pred_train_proba = rf_Grid.predict_proba(X_train)\n",
    "grid_y_pred_train_proba_answer = grid_y_pred_train_proba[:,1]\n",
    "\n",
    "print(grid_y_pred_train[:10])\n",
    "print(grid_y_pred_train_proba[:10])\n",
    "print(grid_y_pred_train_proba_answer[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91     16324\n",
      "           1       0.83      0.45      0.58      4676\n",
      "\n",
      "    accuracy                           0.86     21000\n",
      "   macro avg       0.84      0.71      0.75     21000\n",
      "weighted avg       0.85      0.86      0.84     21000\n",
      "\n",
      "[[15880   444]\n",
      " [ 2578  2098]]\n",
      "0.710737432266073\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, grid_y_pred_train))\n",
    "print(confusion_matrix(y_train, grid_y_pred_train))\n",
    "print(roc_auc_score(y_train, grid_y_pred_train))\n",
    "# Are there signs of overfitting? Why or why not?\n",
    "# It is not overfitting this time because the accuracy score of the train data is similar or even smaller than the testing one.\n",
    "# That means the new model finds a balance between learning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create a feature importance plot for your best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.03791\n",
      "Feature: 1, Score: 0.00361\n",
      "Feature: 2, Score: 0.00905\n",
      "Feature: 3, Score: 0.00554\n",
      "Feature: 4, Score: 0.02727\n",
      "Feature: 5, Score: 0.24391\n",
      "Feature: 6, Score: 0.11031\n",
      "Feature: 7, Score: 0.06589\n",
      "Feature: 8, Score: 0.05322\n",
      "Feature: 9, Score: 0.04059\n",
      "Feature: 10, Score: 0.03910\n",
      "Feature: 11, Score: 0.03475\n",
      "Feature: 12, Score: 0.03336\n",
      "Feature: 13, Score: 0.02908\n",
      "Feature: 14, Score: 0.02763\n",
      "Feature: 15, Score: 0.02748\n",
      "Feature: 16, Score: 0.02783\n",
      "Feature: 17, Score: 0.04375\n",
      "Feature: 18, Score: 0.03194\n",
      "Feature: 19, Score: 0.03047\n",
      "Feature: 20, Score: 0.02679\n",
      "Feature: 21, Score: 0.02500\n",
      "Feature: 22, Score: 0.02552\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get importance\n",
    "importance = rf_Grid.best_estimator_.feature_importances_\n",
    "\n",
    "features = X_train.columns\n",
    "indices = np.argsort(importance)\n",
    "\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "    print('Feature: %0d, Score: %.5f' % (i,v))\n",
    "    \n",
    "# plot feature importance\n",
    "plt.title('Feature importance')\n",
    "\n",
    "plt.barh(range(len(importance)), importance[indices])\n",
    "plt.yticks(range(len(importance)), [features[i] for i in indices])\n",
    "         \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the graph shown above, the top 5 features are: pay_0, pay_2, pay_3, pay_4, and pay_amt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conceptual Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the best parameters from the Grid Search in Question # 3? Does the Model from #3 outperform Model #2?\n",
    "\n",
    "The best parameters are: <br>\n",
    "cv=5, estimator=RandomForestClassifier(), n_jobs=-1, <br>\n",
    "param_grid={'max_depth': [6, 8, 10, 12], <br>\n",
    "                         'max_features': [2, 4, 'sqrt'], <br>\n",
    "                         'min_samples_split': [3, 4, 5, 6, 7, 8], <br>\n",
    "                         'n_estimators': [50, 100, 500]}, <br>\n",
    "                         scoring='roc_auc', verbose=5)} <br>\n",
    "                         \n",
    "---- Yes, it does outperform because the accuracy score for the test data using the model from Q3 is higher than that from Q2. And the model from Q3 deals with the overfitting problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Overfitting is always a concern in ML problems. Does Model #3 overfit data more or less than Model #2? Explain why you think this is the case. \n",
    "\n",
    "---- The model #3 overfit data less than Model #2. Since the accuracy score from test has smaller gap to the training score compared to that of model 2, we can say that the model 3 finds a balance between learning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. The lecture notes describe the Gini Index which is the default criterion used for splitting in sklearn's version of RandomForestClassifier. How does the Gini Index work? (i.e. How is it used to build a top-performing model?). \n",
    "\n",
    "---- Gini Index calculates the amount of probability of a specific feature that is classified incorrectly when selected randomly. It will be smaller if the node becomes more pure. In other words, the better classification is, the smaller gini gets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Describe how Random Forest is different from bagging & why this difference can yield improved results.\n",
    "\n",
    "---- Due to the random feature selection, the trees from random forest model are more independent of each other compared to regular bagging, which often results in better predictive performance (due to better variance-bias trade-offs). Moreover, itâ€™s faster than bagging, because each tree learns only from a subset of features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Describe the importance of the max_depth parameter in Random Forest. Do not just provide a definition, rather think through how bias-variance tradeoff might be impacted by the max_depth parameter.\n",
    "\n",
    "---- The max_depth parameter specifies the maximum depth of each tree. The deeper the tree, the more splits it has and it captures more information about the data. However, if the tree classify in too much details, it may cause overfitting problems. In other words, the more deeper it gets, the more possible it will cause variance problem. However, if it is not classified that clear, the model will go underfit. Thus, we should keep a nice balance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. In this homework we used k-fold cross-validation while determining the optimal hyperparameters for our Random Forest model. 1) Describe how k-fold cross-validation works. 2) What benefit do we gain by using k-fold cross-validation when tuning our Random Forest model versus only using the train-test split approach?\n",
    "\n",
    "---- K-fold cross-validation is a resampling procedure than takes a single parameter called k (the number of groups that a given data sample is to be split into) and split the dataset. For each unique group: we should: 1)Take the group as a hold out or test data set; 2)Take the remaining groups as a training data set; 3)Fit a model on the training set and evaluate it on the test set; 4)Retain the evaluation score and discard the model; 5)Summarize the skill of the model using the sample of model evaluation scores\n",
    "\n",
    "---- The benefit of using k-fold cross valiadation is to optimize the model parameters. By using the k-fold, training happens k times, each time leaving out a different part of the training set. The error of these k-models is averaged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

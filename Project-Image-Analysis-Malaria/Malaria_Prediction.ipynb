{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create the path "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import os\n",
    "# initialize the path to the *original* input directory of images\n",
    "ORIG_INPUT_DATASET = \"malaria/cell_images\"\n",
    "# initialize the base path to the *new* directory that will contain\n",
    "# our images after computing the training and testing split\n",
    "BASE_PATH = \"malaria\"\n",
    "# derive the training, validation, and testing directories\n",
    "TRAIN_PATH = os.path.sep.join([BASE_PATH, \"training\"])\n",
    "VAL_PATH = os.path.sep.join([BASE_PATH, \"validation\"])\n",
    "TEST_PATH = os.path.sep.join([BASE_PATH, \"testing\"])\n",
    "# define the amount of data that will be used training\n",
    "TRAIN_SPLIT = 0.8\n",
    "# the amount of validation data will be a percentage of the\n",
    "# *training* data\n",
    "VAL_SPLIT = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import paths\n",
    "import random\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "imagePaths = list(paths.list_images(ORIG_INPUT_DATASET))\n",
    "random.seed(42)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "i = int(len(imagePaths) * TRAIN_SPLIT)\n",
    "trainPaths = imagePaths[:i]\n",
    "testPaths = imagePaths[i:]\n",
    "# we'll be using part of the training data for validation\n",
    "i = int(len(trainPaths) * VAL_SPLIT)\n",
    "valPaths = trainPaths[:i]\n",
    "trainPaths = trainPaths[i:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create training, testing, and validition dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets that we'll be building\n",
    "datasets = [\n",
    "    (\"training\", trainPaths, TRAIN_PATH),\n",
    "    (\"validation\", valPaths, VAL_PATH),\n",
    "    (\"testing\", testPaths, TEST_PATH)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] building 'training' split\n",
      "[INFO] 'creating malaria/training' directory\n",
      "[INFO] 'creating malaria/training/Parasitized' directory\n",
      "[INFO] 'creating malaria/training/Uninfected' directory\n",
      "[INFO] building 'validation' split\n",
      "[INFO] 'creating malaria/validation' directory\n",
      "[INFO] 'creating malaria/validation/Parasitized' directory\n",
      "[INFO] 'creating malaria/validation/Uninfected' directory\n",
      "[INFO] building 'testing' split\n",
      "[INFO] 'creating malaria/testing' directory\n",
      "[INFO] 'creating malaria/testing/Parasitized' directory\n",
      "[INFO] 'creating malaria/testing/Uninfected' directory\n"
     ]
    }
   ],
   "source": [
    "# loop over the datasets\n",
    "\n",
    "for (dType, imagePaths, baseOutput) in datasets:\n",
    "    # show which data split we are creating\n",
    "    print(\"[INFO] building '{}' split\".format(dType))\n",
    "    \n",
    "    # if the output base output directory does not exist, create it\n",
    "    if not os.path.exists(baseOutput):\n",
    "        print(\"[INFO] 'creating {}' directory\".format(baseOutput))\n",
    "        os.makedirs(baseOutput)\n",
    "\n",
    "    # loop over the input image paths\n",
    "    for inputPath in imagePaths:\n",
    "        # extract the filename of the input image along with its\n",
    "        # corresponding class label\n",
    "        filename = inputPath.split(os.path.sep)[-1]\n",
    "        label = inputPath.split(os.path.sep)[-2]\n",
    "        \n",
    "        # build the path to the label directory\n",
    "        labelPath = os.path.sep.join([baseOutput, label])\n",
    "        \n",
    "        # if the label output directory does not exist, create it\n",
    "        if not os.path.exists(labelPath):\n",
    "            print(\"[INFO] 'creating {}' directory\".format(labelPath))\n",
    "            os.makedirs(labelPath)\n",
    "        \n",
    "        # construct the path to the destination image and then copy\n",
    "        # the image itself\n",
    "        p = os.path.sep.join([labelPath, filename])\n",
    "        shutil.copy2(inputPath, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a model: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 4s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, None, 3)]   0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "conv_base = VGG16(weights = \"imagenet\",include_top = False)\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "totalTrain = len(list(paths.list_images(TRAIN_PATH)))\n",
    "totalVal = len(list(paths.list_images(VAL_PATH)))\n",
    "totalTest = len(list(paths.list_images(TEST_PATH)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the training training data augmentation object\n",
    "trainAug = ImageDataGenerator(\n",
    "    rescale=1 / 255.0,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.05,\n",
    "    width_shift_range=0.05,\n",
    "    height_shift_range=0.05,\n",
    "    shear_range=0.05,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")\n",
    "\n",
    "# initialize the validation (and testing) data augmentation object\n",
    "valAug = ImageDataGenerator(rescale=1 / 255.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define train, test, validation generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19842 images belonging to 2 classes.\n",
      "Found 2204 images belonging to 2 classes.\n",
      "Found 5512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# initialize the training generator\n",
    "trainGen = trainAug.flow_from_directory(\n",
    "    TRAIN_PATH,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=200)\n",
    "\n",
    "# initialize the validation generator\n",
    "valGen = valAug.flow_from_directory(\n",
    "    VAL_PATH,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=200)\n",
    "\n",
    "# initialize the testing generator\n",
    "testGen = valAug.flow_from_directory(\n",
    "    TEST_PATH,\n",
    "    class_mode=\"binary\",\n",
    "    target_size=(150, 150),\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the datasets that we will build\n",
    "generator = [\n",
    "    ('training', trainGen),\n",
    "    ('validation', valGen),\n",
    "    ('testing', testGen)\n",
    "]\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "def extract_features(generator, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 4, 4, 512))\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    i = 0\n",
    "\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        #print(labels_batch)\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i+1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i+1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if ((i * batch_size % 1000) == 0 ):\n",
    "            print(\"processed size =\", i * batch_size)\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "            \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed size = 1000\n",
      "processed size = 2000\n"
     ]
    }
   ],
   "source": [
    "valFeatures, valLabels = extract_features(valGen, 2204)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed size = 1000\n",
      "processed size = 2000\n",
      "processed size = 3000\n",
      "processed size = 4000\n",
      "processed size = 5000\n",
      "processed size = 6000\n",
      "processed size = 7000\n",
      "processed size = 8000\n",
      "processed size = 9000\n",
      "processed size = 10000\n",
      "processed size = 11000\n",
      "processed size = 12000\n",
      "processed size = 13000\n",
      "processed size = 14000\n",
      "processed size = 15000\n",
      "processed size = 16000\n",
      "processed size = 17000\n",
      "processed size = 18000\n",
      "processed size = 19000\n",
      "processed size = 20000\n"
     ]
    }
   ],
   "source": [
    "trainFeatures, trainLabels = extract_features(trainGen, 19842)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed size = 1000\n",
      "processed size = 2000\n",
      "processed size = 3000\n",
      "processed size = 4000\n",
      "processed size = 5000\n"
     ]
    }
   ],
   "source": [
    "testFeatures, testLabels = extract_features(testGen, 5512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('trainFeatures', trainFeatures)\n",
    "np.save('trainLabels', trainLabels)\n",
    "\n",
    "np.save('testFeatures', testFeatures)\n",
    "np.save('testLabels', testLabels)\n",
    "\n",
    "np.save('valFeatures', valFeatures)\n",
    "np.save('valLabels', valLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "trainFeatures = np.load('trainFeatures.npy')\n",
    "trainLabels = np.load('trainLabels.npy')\n",
    "\n",
    "testFeatures = np.load('testFeatures.npy')\n",
    "testLabels = np.load('testLabels.npy')\n",
    "\n",
    "valFeatures = np.load('valFeatures.npy')\n",
    "valLabels = np.load('valLabels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19842, 4, 4, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.reshape(trainFeatures, (len(trainFeatures), 4 * 4 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19842, 8192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5512, 4, 4, 512)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5512, 8192)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_features = np.reshape(testFeatures, (len(testFeatures), 4 * 4 * 512))\n",
    "test_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204, 4, 4, 512)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valFeatures.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2204, 8192)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_features = np.reshape(valFeatures, (len(valFeatures), 4 * 4 * 512))\n",
    "val_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = [\"Parasitized\", \"Uninfected\"]\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(4 * 4 * 512,), activation=\"relu\"))\n",
    "model.add(Dense(16, activation=\"relu\"))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "opt = Adam(learning_rate=2e-3)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training simple network...\n",
      "Epoch 1/25\n",
      "99/99 [==============================] - 4s 38ms/step - loss: 0.6289 - accuracy: 0.7565 - val_loss: 0.2660 - val_accuracy: 0.8932\n",
      "Epoch 2/25\n",
      "99/99 [==============================] - 3s 29ms/step - loss: 0.2127 - accuracy: 0.9210 - val_loss: 0.2489 - val_accuracy: 0.8973\n",
      "Epoch 3/25\n",
      "99/99 [==============================] - 3s 27ms/step - loss: 0.1768 - accuracy: 0.9367 - val_loss: 0.3088 - val_accuracy: 0.8814\n",
      "Epoch 4/25\n",
      "99/99 [==============================] - 3s 26ms/step - loss: 0.1781 - accuracy: 0.9323 - val_loss: 0.2582 - val_accuracy: 0.9005\n",
      "Epoch 5/25\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.1598 - accuracy: 0.9434 - val_loss: 0.2054 - val_accuracy: 0.9273\n",
      "Epoch 6/25\n",
      "99/99 [==============================] - 3s 27ms/step - loss: 0.1393 - accuracy: 0.9507 - val_loss: 0.2046 - val_accuracy: 0.9291\n",
      "Epoch 7/25\n",
      "99/99 [==============================] - 3s 30ms/step - loss: 0.1263 - accuracy: 0.9558 - val_loss: 0.2424 - val_accuracy: 0.9164\n",
      "Epoch 8/25\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.1263 - accuracy: 0.9552 - val_loss: 0.2352 - val_accuracy: 0.9182\n",
      "Epoch 9/25\n",
      "99/99 [==============================] - 3s 30ms/step - loss: 0.1307 - accuracy: 0.9523 - val_loss: 0.2815 - val_accuracy: 0.9041\n",
      "Epoch 10/25\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.1110 - accuracy: 0.9594 - val_loss: 0.2507 - val_accuracy: 0.9114\n",
      "Epoch 11/25\n",
      "99/99 [==============================] - 2s 23ms/step - loss: 0.1166 - accuracy: 0.9583 - val_loss: 0.2268 - val_accuracy: 0.9273\n",
      "Epoch 12/25\n",
      "99/99 [==============================] - 3s 34ms/step - loss: 0.0959 - accuracy: 0.9652 - val_loss: 0.2708 - val_accuracy: 0.9155\n",
      "Epoch 13/25\n",
      "99/99 [==============================] - 3s 28ms/step - loss: 0.1155 - accuracy: 0.9569 - val_loss: 0.2652 - val_accuracy: 0.9155\n",
      "Epoch 14/25\n",
      "99/99 [==============================] - 3s 30ms/step - loss: 0.0942 - accuracy: 0.9648 - val_loss: 0.2573 - val_accuracy: 0.9205\n",
      "Epoch 15/25\n",
      "99/99 [==============================] - 3s 31ms/step - loss: 0.0770 - accuracy: 0.9730 - val_loss: 0.2664 - val_accuracy: 0.9123\n",
      "Epoch 16/25\n",
      "99/99 [==============================] - 2s 25ms/step - loss: 0.1063 - accuracy: 0.9607 - val_loss: 0.2981 - val_accuracy: 0.9118\n",
      "Epoch 17/25\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.0737 - accuracy: 0.9742 - val_loss: 0.2697 - val_accuracy: 0.9186\n",
      "Epoch 18/25\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.0623 - accuracy: 0.9793 - val_loss: 0.2649 - val_accuracy: 0.9227\n",
      "Epoch 19/25\n",
      "99/99 [==============================] - 2s 22ms/step - loss: 0.0637 - accuracy: 0.9774 - val_loss: 0.3069 - val_accuracy: 0.9173\n",
      "Epoch 20/25\n",
      "99/99 [==============================] - 2s 23ms/step - loss: 0.0598 - accuracy: 0.9791 - val_loss: 0.4095 - val_accuracy: 0.8918\n",
      "Epoch 21/25\n",
      "99/99 [==============================] - 2s 23ms/step - loss: 0.0662 - accuracy: 0.9761 - val_loss: 0.3007 - val_accuracy: 0.9159\n",
      "Epoch 22/25\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.0864 - accuracy: 0.9680 - val_loss: 0.3388 - val_accuracy: 0.9100\n",
      "Epoch 23/25\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.0511 - accuracy: 0.9821 - val_loss: 0.3164 - val_accuracy: 0.9164\n",
      "Epoch 24/25\n",
      "99/99 [==============================] - 2s 24ms/step - loss: 0.0506 - accuracy: 0.9818 - val_loss: 0.3256 - val_accuracy: 0.9173\n",
      "Epoch 25/25\n",
      "99/99 [==============================] - 2s 25ms/step - loss: 0.0528 - accuracy: 0.9810 - val_loss: 0.3056 - val_accuracy: 0.9223\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=200\n",
    "print(\"[INFO] training simple network...\")\n",
    "H = model.fit(\n",
    "    train_features.reshape(19842, 8192), trainLabels, batch_size=200, \n",
    "    steps_per_epoch=19842 // 200,\n",
    "    validation_data= (val_features.reshape(2204,8192), valLabels),\n",
    "    validation_steps=2204 // 200,\n",
    "    epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.92      0.94      2726\n",
      "         1.0       0.92      0.96      0.94      2786\n",
      "\n",
      "    accuracy                           0.94      5512\n",
      "   macro avg       0.94      0.94      0.94      5512\n",
      "weighted avg       0.94      0.94      0.94      5512\n",
      "\n",
      "28/28 [==============================] - 0s 13ms/step - loss: 0.2340 - accuracy: 0.9381\n",
      "test acc:  0.9381349682807922\n"
     ]
    }
   ],
   "source": [
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(x=test_features.reshape(5512,8192),\n",
    "    steps=(5512 // 200) + 1)\n",
    "#predIdxs = np.argmax(predIdxs, axis=1)\n",
    "print(classification_report(testLabels, (predIdxs>0.5).astype(int)))\n",
    "\n",
    "accuracy = model.evaluate(x=test_features, y=testLabels, batch_size=200)\n",
    "print('test acc: ', accuracy[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the final accuracy score is 0.9381"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
